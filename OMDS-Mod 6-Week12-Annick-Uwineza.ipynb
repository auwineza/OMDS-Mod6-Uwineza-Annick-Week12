{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee3a6979",
   "metadata": {},
   "source": [
    "# Week 12 Coding Homework Notebook\n",
    "\n",
    "This notebook is a template to help you answer the Week 12 coding quiz questions.\n",
    "You can upload the datasets provided by your course to this environment and update the file paths as needed.\n",
    "\n",
    "**Questions covered:**\n",
    "1. Difference-in-differences effect for Dataset 12.1\n",
    "2. Prior trends test (interaction of Group × Time) for Dataset 12.2\n",
    "3. Autocorrelated errors simulation and comparison of OLS SE vs simulation SD of the coefficient\n",
    "4. Variance inflation factor (VIF) for X1 in a collinearity example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83266efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "np.random.seed(0)\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623fbd5b",
   "metadata": {},
   "source": [
    "## Question 1 – DID effect in Dataset 12.1\n",
    "\n",
    "**Prompt summary:**\n",
    "- Dataset 12.1\n",
    "- `Group = 1` is the treatment group, `Group = 0` is control\n",
    "- `Time > 0` is the treatment period, `Time <= 0` is pre-treatment\n",
    "- Outcome variable is assumed to be `Y`\n",
    "\n",
    "We want the difference-in-differences (DID) treatment effect.\n",
    "\n",
    "Steps:\n",
    "1. Load the dataset\n",
    "2. Compute average Y by group and period\n",
    "3. Compute DID manually\n",
    "4. (Optional) Confirm via a regression with an interaction term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Question 1: Load Dataset 12.1 and compute DID effect ===\n",
    "\n",
    "# TODO: Update the file name/path to match where you upload the dataset\n",
    "data_path_q1 = 'homework_12.1.csv'  # change if needed\n",
    "\n",
    "df1 = pd.read_csv(data_path_q1)\n",
    "print('Data 12.1 shape:', df1.shape)\n",
    "display(df1.head())\n",
    "\n",
    "# Create indicators for treatment group and post period\n",
    "df1['treat'] = (df1['Group'] == 1).astype(int)\n",
    "df1['post'] = (df1['Time'] > 0).astype(int)\n",
    "\n",
    "# 1) Manual DID using group means\n",
    "group_means = (\n",
    "    df1\n",
    "    .groupby(['treat', 'post'])['Y']\n",
    "    .mean()\n",
    "    .unstack('post')\n",
    ")\n",
    "group_means.columns = ['pre', 'post']  # 0 = pre, 1 = post\n",
    "display(group_means)\n",
    "\n",
    "treat_change = group_means.loc[1, 'post'] - group_means.loc[1, 'pre']\n",
    "control_change = group_means.loc[0, 'post'] - group_means.loc[0, 'pre']\n",
    "did_effect = treat_change - control_change\n",
    "\n",
    "print('Treatment group change:', treat_change)\n",
    "print('Control group change:  ', control_change)\n",
    "print('DID effect (manual):   ', did_effect)\n",
    "\n",
    "# 2) DID via regression: Y ~ treat + post + treat:post\n",
    "model_q1 = ols('Y ~ treat + post + treat:post', data=df1).fit()\n",
    "print(model_q1.summary())\n",
    "print('\\nDID effect from regression (treat:post coefficient):', model_q1.params['treat:post'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b72a5a9",
   "metadata": {},
   "source": [
    "## Question 2 – Prior trends in Dataset 12.2\n",
    "\n",
    "**Prompt summary:**\n",
    "- Use Dataset 12.2\n",
    "- Use only data *before* `Time = 0` (i.e., `Time < 0`)\n",
    "- Run a linear regression:\n",
    "  \\( Y = \\beta_0 + \\beta_1 \\text{Time} + \\beta_2 \\text{Group} + \\beta_3 (\\text{Group} \\times \\text{Time}) + \\varepsilon \\)\n",
    "- We want the **t-value** for the interaction term `Group × Time`\n",
    "\n",
    "Steps:\n",
    "1. Load the dataset\n",
    "2. Filter to `Time < 0`\n",
    "3. Fit the regression with interaction\n",
    "4. Extract and print the t-value of the interaction term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Question 2: Prior trends test in Dataset 12.2 ===\n",
    "\n",
    "# TODO: Update file name/path if needed\n",
    "data_path_q2 = 'homework_12.2.csv'\n",
    "\n",
    "df2 = pd.read_csv(data_path_q2)\n",
    "print('Data 12.2 shape:', df2.shape)\n",
    "display(df2.head())\n",
    "\n",
    "# Keep only pre-treatment observations: Time < 0\n",
    "df2_pre = df2[df2['Time'] < 0].copy()\n",
    "print('Pre-treatment subset shape:', df2_pre.shape)\n",
    "\n",
    "# Ensure Group is treated as numeric (0/1)\n",
    "df2_pre['Group'] = df2_pre['Group'].astype(int)\n",
    "\n",
    "# Regression: Y ~ Time + Group + Group:Time\n",
    "model_q2 = ols('Y ~ Time * Group', data=df2_pre).fit()\n",
    "print(model_q2.summary())\n",
    "\n",
    "# Extract t-value for the Group:Time interaction term\n",
    "t_interaction = model_q2.tvalues['Time:Group']\n",
    "print('\\nT-value for Group × Time interaction:', t_interaction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c7457",
   "metadata": {},
   "source": [
    "## Question 3 – Autocorrelated errors simulation\n",
    "\n",
    "**Prompt summary:**\n",
    "- Generate an error series `e_t` of length 10,000\n",
    "- Correlation between `e_t` and `e_{t+1}` should be about 0.8\n",
    "- Mean of error ≈ 0, standard deviation ≈ 1\n",
    "- Let `X = e` (the error)\n",
    "- Let `Y = 2*X + new_error` (new independent error with the same properties)\n",
    "- Compute:\n",
    "  - OLS standard error of the `X` coefficient in a single regression\n",
    "  - Simulation standard deviation of the coefficient by repeating the whole process many times\n",
    "\n",
    "We expect the **simulation SD** of the coefficient to be larger than the naive OLS SE because of autocorrelation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Question 3: Autocorrelated errors and simulation ===\n",
    "\n",
    "def generate_ar1_errors(n=10000, rho=0.8):\n",
    "    \"\"\"Generate AR(1) errors with correlation rho and approx sd=1.\"\"\"\n",
    "    eps_sd = np.sqrt(1 - rho**2)  # so that stationary variance is 1\n",
    "    eps = np.random.normal(0, eps_sd, size=n)\n",
    "    e = np.zeros(n)\n",
    "    for t in range(1, n):\n",
    "        e[t] = rho * e[t-1] + eps[t]\n",
    "    return e\n",
    "\n",
    "# Single run: check properties\n",
    "n = 10000\n",
    "rho_target = 0.8\n",
    "e = generate_ar1_errors(n=n, rho=rho_target)\n",
    "print('Mean error:', np.mean(e))\n",
    "print('Std error: ', np.std(e))\n",
    "print('Lag-1 correlation (e_t, e_{t+1}):', np.corrcoef(e[:-1], e[1:])[0, 1])\n",
    "\n",
    "# Construct X and Y for the regression\n",
    "X = e\n",
    "new_error = generate_ar1_errors(n=n, rho=rho_target)\n",
    "Y = 2 * X + new_error\n",
    "\n",
    "X_mat = sm.add_constant(X)\n",
    "ols_res = sm.OLS(Y, X_mat).fit()\n",
    "beta_hat = ols_res.params[1]\n",
    "se_naive = ols_res.bse[1]\n",
    "\n",
    "print('\\nSingle-run OLS estimate of beta:', beta_hat)\n",
    "print('Naive OLS standard error:        ', se_naive)\n",
    "\n",
    "# Simulation over many repetitions\n",
    "R = 200  # you can increase this if you have time\n",
    "beta_hats = []\n",
    "for r in range(R):\n",
    "    e = generate_ar1_errors(n=n, rho=rho_target)\n",
    "    X = e\n",
    "    new_error = generate_ar1_errors(n=n, rho=rho_target)\n",
    "    Y = 2 * X + new_error\n",
    "    X_mat = sm.add_constant(X)\n",
    "    res = sm.OLS(Y, X_mat).fit()\n",
    "    beta_hats.append(res.params[1])\n",
    "\n",
    "beta_hats = np.array(beta_hats)\n",
    "sim_sd = beta_hats.std(ddof=1)\n",
    "\n",
    "print('\\nSimulation results (R =', R, ')')\n",
    "print('Mean of beta_hat over simulations:', beta_hats.mean())\n",
    "print('SD of beta_hat over simulations:  ', sim_sd)\n",
    "print('\\nCompare: naive OLS SE vs simulation SD')\n",
    "print('Naive OLS SE (single run):', se_naive)\n",
    "print('Simulation SD:            ', sim_sd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39735d11",
   "metadata": {},
   "source": [
    "## Question 4 – Variance Inflation Factor (VIF) of X1\n",
    "\n",
    "**Prompt summary:**\n",
    "We generate:\n",
    "```python\n",
    "np.random.seed(0)\n",
    "X1 = np.random.normal(0, 1, 1000)\n",
    "X2 = np.random.normal(0, 1, 1000) + X1\n",
    "X3 = np.random.normal(0, 1, 1000) + 2 * X2\n",
    "```\n",
    "\n",
    "We want the **VIF of X1**, which is:\n",
    "\\( \\text{VIF}_{X1} = 1 / (1 - R^2) \\), where \\( R^2 \\) is from regressing X1 on X2 and X3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e8e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Question 4: VIF for X1 ===\n",
    "\n",
    "np.random.seed(0)\n",
    "X1 = np.random.normal(0, 1, 1000)\n",
    "X2 = np.random.normal(0, 1, 1000) + X1\n",
    "X3 = np.random.normal(0, 1, 1000) + 2 * X2\n",
    "\n",
    "df_vif = pd.DataFrame({'X1': X1, 'X2': X2, 'X3': X3})\n",
    "\n",
    "# Regress X1 on X2 and X3\n",
    "X_mat = sm.add_constant(df_vif[['X2', 'X3']])\n",
    "res_vif = sm.OLS(df_vif['X1'], X_mat).fit()\n",
    "R2 = res_vif.rsquared\n",
    "vif_X1 = 1 / (1 - R2)\n",
    "\n",
    "print(res_vif.summary())\n",
    "print('\\nR^2 for regression of X1 on X2 and X3:', R2)\n",
    "print('VIF for X1:', vif_X1)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
